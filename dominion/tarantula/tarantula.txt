In order to try and localize a bug using the tarantula method I wrote a python script (tarantula.py) that counts the lines in a gcov file, counts the lines read, and using pass/fail information determines the relative suspiciousness of lines. I have this script loop over 10 different gcov files to determine the relative suspiciousness of each line in dominion.c.

This method worked well for finding the location of a suspected bug in my dominion.c file. The tarantula script I wrote identified two suspicious areas of code. The first is the playCard() function and the second area is the whoseTurn() function. This makes sense because my failing test is a unit test of playCard() and playCard() calls whoseTurn().

I am glad that tarantula was able to idetnify the area in which my code may be broken, but unfortunately it did not actually give me any new information. I feel that if I had more failing tests I would potentially have gained more information about where a bug in my code may be hiding. Because I only have four unit tests and four card tests on this code, the number of bugs I can catch and failing test cases I have is very small. If I had a more thorough suit with comprehensive unit testing I feel that tarantula would provide me with a lot more useful information.

Output:
line		suspiciousness
 231		1.00
 234		1.00
 237		1.00
 243		1.00
 249		1.00
 252		1.00
 254		1.00
 315		1.00
 316		1.00
 317		1.00
 346		0.56
 347		0.56
   8		0.50
   9		0.50
  11		0.50
  12		0.50
  13		0.50
  37		0.50
  44		0.50
  45		0.50
  48		0.50
  54		0.50
  57		0.50
  59		0.50
  61		0.50
  73		0.50
  75		0.50
  87		0.50
  89		0.50
  90		0.50
  91		0.50
 101		0.50
 102		0.50
 103		0.50
 106		0.50
 108		0.50
 110		0.50
 113		0.50
 115		0.50
 116		0.50
 122		0.50
 124		0.50
 128		0.50
 138		0.50
 140		0.50
 141		0.50
 143		0.50
 144		0.50
 146		0.50
 148		0.50
 149		0.50
 154		0.50
 156		0.50
 163		0.50
 166		0.50
 167		0.50
 176		0.50
 178		0.50
 182		0.50
 183		0.50
 184		0.50
 185		0.50
 186		0.50
 187		0.50
 188		0.50
 192		0.50
 193		0.50
 196		0.50
 198		0.50
 201		0.50
 205		0.50
 209		0.50
 211		0.50
 214		0.50
 215		0.50
 216		0.50
 217		0.50
 218		0.50
 219		0.50
 221		0.50
 223		0.50
 224		0.50
 225		0.50
 228		0.50
 525		0.50
 528		0.50
 568		0.50
 574		0.50
 575		0.50
 576		0.50
 577		0.50
 580		0.50
1236		0.50
1241		0.50
1244		0.50
1246		0.50
1248		0.50
1250		0.50
1254		0.50
1261		0.50
